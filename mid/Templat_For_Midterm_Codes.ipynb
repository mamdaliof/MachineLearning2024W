{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Libraries"
      ],
      "metadata": {
        "id": "2Jb1IugDb0wG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import itertools\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.metrics import r2_score\n",
        "from scipy.io import loadmat\n",
        "import numpy as np\n",
        "from scipy.stats import skew, kurtosis\n",
        "from sklearn.utils import shuffle\n",
        "from sklearn.model_selection import train_test_split\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense\n",
        "from scipy.io import loadmat\n",
        "from scipy.stats import skew, kurtosis\n",
        "from sklearn.utils import shuffle\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.datasets import fetch_covtype\n",
        "from sklearn import tree\n",
        "from sklearn.utils import resample\n",
        "from pandas import DataFrame as df\n",
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "from keras.optimizers import Adam\n",
        "from keras.optimizers.schedules import PiecewiseConstantDecay"
      ],
      "metadata": {
        "id": "Wy0MY8UWb4LF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Data prepration"
      ],
      "metadata": {
        "id": "spVBlosI9mgX"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##read data (csv)"
      ],
      "metadata": {
        "id": "XZmCp5V3kXQu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!gdown 1vKBjVeSaOsyBIwojXj9F7T66CRHWtXvW\n",
        "\n",
        "data = pd.read_csv('/content/Admission_Predict.csv')\n",
        "\n",
        "data.head()\n",
        "\n",
        "data.info()\n",
        "\n",
        "data.describe()\n",
        "\n"
      ],
      "metadata": {
        "id": "38EFc9sBkch7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## data distrubiution"
      ],
      "metadata": {
        "id": "Hj_ZvW-yk6Me"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "# Visualize the distribution of each column\n",
        "for column in data.select_dtypes(include=['float64', 'int64']).columns:\n",
        "    plt.figure(figsize=(8, 4))\n",
        "    sns.histplot(data[column], kde=True)\n",
        "    plt.title(f'Distribution of {column}')\n",
        "    plt.show()"
      ],
      "metadata": {
        "id": "IfELOowsk3HN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#for 1 or 2\n",
        "\n",
        "# Specify the columns to plot\n",
        "column1 = 'Chance_of_Admit '  # Replace with the actual column name\n",
        "column2 = 'CGPA'  # Replace with the actual column name\n",
        "\n",
        "# Plot distribution for the first column\n",
        "plt.figure(figsize=(14, 6))\n",
        "\n",
        "plt.subplot(1, 2, 1)\n",
        "sns.histplot(Admition_data[column1], kde=True, color='blue')\n",
        "plt.title(f'Distribution of {column1}')\n",
        "\n",
        "# Plot distribution for the second column\n",
        "plt.subplot(1, 2, 2)\n",
        "sns.histplot(Admition_data[column2], kde=True, color='green')\n",
        "plt.title(f'Distribution of {column2}')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "JBAm4IMjlZEN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## corolation matrix"
      ],
      "metadata": {
        "id": "5vTyqSNflCRW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "correlation_matrix = data.corr()\n",
        "\n",
        "plt.figure(figsize=(10, 8))\n",
        "sns.heatmap(correlation_matrix, annot=True, cmap='coolwarm', fmt=\".2f\")\n",
        "plt.title('Correlation Matrix')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "YaVyNQW2lEtn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#for ascending\n",
        "\n",
        "# Specify the column of interest\n",
        "first_column = data.columns[-1]\n",
        "\n",
        "# Compute the correlation of all columns with the specific column\n",
        "correlation_with_specific = data.corr()[first_column].sort_values(ascending=False)\n",
        "\n",
        "# Exclude the specific column itself from the plot (optional)\n",
        "correlation_with_specific = correlation_with_specific.drop(first_column)\n",
        "\n",
        "# Plot the correlations using a bar plot\n",
        "plt.figure(figsize=(10, 8))\n",
        "sns.barplot(x=correlation_with_specific.values, y=correlation_with_specific.index, palette='coolwarm')\n",
        "plt.title(f'Correlation of All Columns with {first_column}')\n",
        "plt.xlabel('Correlation Coefficient')\n",
        "plt.ylabel('Columns')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "pIjpZP4vlNJX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## drop out a column"
      ],
      "metadata": {
        "id": "pADpBrKxlUrn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Drop the 'Age' column\n",
        "Admition_data = Admition_data.drop(columns=['Serial No.'])"
      ],
      "metadata": {
        "id": "ESDHre5ylum-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Shuffle data"
      ],
      "metadata": {
        "id": "SRm4Gl3o9RZP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.utils import shuffle\n",
        "\n",
        "shuffled_final_data = shuffle(data, random_state=4)\n",
        "shuffled_final_data"
      ],
      "metadata": {
        "id": "iFZ8rQJR9VP0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "3udDk3lc9VNg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## X&Y split"
      ],
      "metadata": {
        "id": "sKvVc7G09T3k"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X = shuffled_final_data.drop(columns=['Chance_of_Admit ']).values\n",
        "y = shuffled_final_data['Chance_of_Admit '].values\n",
        "\n",
        "print(\"X :\",X.shape)\n",
        "print(\"y :\",y.shape)"
      ],
      "metadata": {
        "id": "odANEJ8Q8b3d"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Train test split"
      ],
      "metadata": {
        "id": "zJ2psBXf84WH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "X_train_d, X_test_d, y_train_d, y_test_d = train_test_split(X_drug, y_drug, random_state=4, test_size=0.15)\n",
        "X_train_d.shape, X_test_d.shape"
      ],
      "metadata": {
        "id": "01y63YSJ8bym"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## reshape y"
      ],
      "metadata": {
        "id": "0UbGGxFu-Brb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Reshape y_train and y_test\n",
        "y_train = np.reshape(y_train, (-1, 1))\n",
        "y_test = np.reshape(y_test, (-1, 1))\n",
        "x_train.shape, x_test.shape, y_train.shape, y_test.shape"
      ],
      "metadata": {
        "id": "tUYdLOaF-BTe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Normalization"
      ],
      "metadata": {
        "id": "TT9zSvoK-G0e"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import MinMaxScaler, StandardScaler\n",
        "\n",
        "# Initialize MinMaxScaler\n",
        "scaler = MinMaxScaler()\n",
        "\n",
        "scaler.fit(x_train)\n",
        "x_train = scaler.transform(x_train)\n",
        "x_test = scaler.transform(x_test)"
      ],
      "metadata": {
        "id": "D5j3t2-4-BQ9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Train with MPL"
      ],
      "metadata": {
        "id": "M7B3u6YeEnY-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## For regression"
      ],
      "metadata": {
        "id": "cX_YgUkvErlb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.models import Sequential\n",
        "from keras.layers import Dense"
      ],
      "metadata": {
        "id": "yR-n89r5E1Om"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "history.history.keys()"
      ],
      "metadata": {
        "id": "ATn4onhcK_ze"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Initialize the Sequential model\n",
        "model_1 = Sequential()\n",
        "\n",
        "# Add a hidden layer with 50 neurons and ReLU activation function\n",
        "model_1.add(Dense(50, activation='relu', input_shape=(x_train.shape[1],)))\n",
        "\n",
        "# Add an output layer with 1 neuron and linear activation function\n",
        "model_1.add(Dense(1, activation='linear'))\n",
        "\n",
        "model_1.summary()"
      ],
      "metadata": {
        "id": "e_RjCb-aE9jm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_2 = Sequential()\n",
        "\n",
        "# Add the first hidden layer with 50 neurons and linear activation function\n",
        "model_2.add(Dense(50, activation='linear', input_shape=(x_train.shape[1],)))\n",
        "\n",
        "# Add the second hidden layer with 30 neurons and linear activation function\n",
        "model_2.add(Dense(30, activation='linear'))\n",
        "\n",
        "# Add an output layer with 1 neuron and linear activation function\n",
        "model_2.add(Dense(1, activation='linear'))\n",
        "\n",
        "model_2.summary()"
      ],
      "metadata": {
        "id": "e4sTXXyy-BOE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_3 = Sequential()\n",
        "\n",
        "# Add the first hidden layer with 50 neurons and ReLU activation function\n",
        "model_3.add(Dense(50, activation='relu', input_shape=(x_train.shape[1],)))\n",
        "\n",
        "# Add the second hidden layer with 30 neurons and ReLU activation function\n",
        "model_3.add(Dense(30, activation='relu'))\n",
        "\n",
        "# Add the third hidden layer with 10 neurons and ReLU activation function\n",
        "model_3.add(Dense(10, activation='relu'))\n",
        "\n",
        "# Add an output layer with 1 neuron and linear activation function\n",
        "model_3.add(Dense(1, activation='linear'))\n",
        "\n",
        "model_3.summary()"
      ],
      "metadata": {
        "id": "CI6gsES1Ef1Y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_3.compile(optimizer='adam', loss='mse' , metrics=['accuracy'])\n",
        "history = model_3.fit(x_train, y_train, validation_split=0.1, epochs=100, batch_size=10)"
      ],
      "metadata": {
        "id": "_VwPZ7psFtwY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## For classification"
      ],
      "metadata": {
        "id": "xI_vssrnFETz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model_2 = Sequential()\n",
        "\n",
        "# Add the first hidden layer with 50 neurons and linear activation function\n",
        "model_2.add(Dense(15, activation='relu', input_shape=(x_train.shape[1],)))\n",
        "\n",
        "# Add the second hidden layer with 30 neurons and linear activation function\n",
        "model_2.add(Dense(8, activation='relu'))\n",
        "\n",
        "# Add an output layer with 1 neuron and linear activation function\n",
        "model_2.add(Dense(4, activation='softmax'))\n",
        "\n",
        "model_2.summary()"
      ],
      "metadata": {
        "id": "ck6cwsCI-BL9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_2.compile(optimizer='adam', loss='SparseCategoricalCrossentropy', metrics=['accuracy'])\n",
        "history = model_2.fit(x_train, y_train, validation_split=0.1, epochs=100 ,batch_size=10)"
      ],
      "metadata": {
        "id": "CAtJcCK6-BJu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "31vCQOZPF4kb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Plot"
      ],
      "metadata": {
        "id": "B1jQ5j5CLElC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Plot the training and validation loss\n",
        "plt.plot(history.history['loss'], label='train')   # Training loss\n",
        "plt.plot(history.history['val_loss'], label='val')  # Validation loss\n",
        "\n",
        "plt.legend(['Training Loss', 'Validation Loss'])\n",
        "plt.xlabel(\"Epochs\")\n",
        "plt.ylabel(\"Loss\")\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "ABnqpPj3-BHH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Plot accuracy\n",
        "plt.plot(history.history['accuracy'], label='Training Accuracy')\n",
        "plt.plot(history.history['val_accuracy'], label='Validation Accuracy')\n",
        "\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.title('Accuracy over Epochs')\n",
        "plt.legend()\n",
        "\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "6F2FfFl--BFC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Drop out / Learning Rate Scheduler / Early Stopping"
      ],
      "metadata": {
        "id": "wT7Dkh8OXLku"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model_4 = Sequential()\n",
        "\n",
        "# Add the first hidden layer with 50 neurons and ReLU activation function\n",
        "model_4.add(Dense(30, activation='relu', input_shape=(x_train.shape[1],)))\n",
        "model_3.add(Dropout(0.5))  # Dropout layer with 50% dropout rate\n",
        "\n",
        "\n",
        "# Add the third hidden layer with 10 neurons and ReLU activation function\n",
        "model_4.add(Dense(10, activation='relu'))\n",
        "model_3.add(Dropout(0.5))  # Dropout layer with 50% dropout rate\n",
        "\n",
        "\n",
        "# Add an output layer with 1 neuron and linear activation function\n",
        "model_4.add(Dense(1, activation='linear'))\n",
        "\n",
        "model_4.summary()"
      ],
      "metadata": {
        "id": "rh5mU9ij-BCp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.callbacks import EarlyStopping\n",
        "\n",
        "# Define the Early Stopping callback\n",
        "early_stopping = EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True)\n",
        "\n",
        "# Compile your model\n",
        "model_4.compile(optimizer='adam', loss='mse')\n",
        "\n",
        "# Fit the model with Early Stopping callback\n",
        "history = model_4.fit(x_train, y_train_d, validation_split=0.1, epochs=1000, batch_size=10, callbacks=[early_stopping])\n"
      ],
      "metadata": {
        "id": "sSUBulKg-A_t"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.optimizers import Adam\n",
        "from keras.optimizers.schedules import PiecewiseConstantDecay\n",
        "\n",
        "# Define the learning rate schedule\n",
        "boundaries = [50, 100, 150]  # Boundaries where learning rate changes\n",
        "values = [0.001, 0.001, 0.001, 0.001]  # Learning rate values for each interval\n",
        "\n",
        "# Create a PiecewiseConstantDecay learning rate schedule\n",
        "lr_schedule = PiecewiseConstantDecay(boundaries, values)\n",
        "\n",
        "# Create an optimizer with Adam and PiecewiseConstantDecay learning rate\n",
        "optimizer = Adam(learning_rate=lr_schedule)\n",
        "\n"
      ],
      "metadata": {
        "id": "N454Mu7Z-AxX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.optimizers.schedules import ExponentialDecay, PolynomialDecay\n",
        "\n",
        "\n",
        "# Define the parameters for PolynomialDecay\n",
        "initial_learning_rate = 0.001\n",
        "decay_steps = 1000\n",
        "end_learning_rate = 0.0001\n",
        "power = 0.5  # The power of the polynomial decay\n",
        "\n",
        "# Create a PolynomialDecay learning rate schedule\n",
        "lr_schedule = PolynomialDecay(\n",
        "    initial_learning_rate=initial_learning_rate,\n",
        "    decay_steps=decay_steps,\n",
        "    end_learning_rate=end_learning_rate,\n",
        "    power=power\n",
        ")\n",
        "\n",
        "optimizer=Adam(learning_rate=lr_schedule)"
      ],
      "metadata": {
        "id": "aDqrPPr98bv4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# confution matrix & metrics"
      ],
      "metadata": {
        "id": "b4aQ5yU6l95m"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
        "\n",
        "y_pred_classes = np.argmax(y_pred_2_2, axis=1)  # Convert predicted probabilities to class labels\n",
        "\n",
        "cm = confusion_matrix(y_test_d, y_pred)\n",
        "\n",
        "target_names = ['A', 'B', 'C', 'X', 'Y']\n",
        "\n",
        "disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=target_names)\n",
        "disp.plot(cmap=plt.cm.Blues)\n",
        "plt.title('Confusion Matrix')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "qc-tQXH6i7mN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import accuracy_score, precision_score, recall_score\n",
        "\n",
        "accuracy = accuracy_score(y_test_d, y_pred)\n",
        "precision = precision_score(y_test_d, y_pred, average='weighted')\n",
        "recall = recall_score(y_test_d, y_pred, average='weighted')\n",
        "\n",
        "print(\"Accuracy:\", accuracy)\n",
        "print(\"Precision:\", precision)\n",
        "print(\"Recall:\", recall)\n"
      ],
      "metadata": {
        "id": "vGvhZ5DAi7j2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import classification_report\n",
        "print(classification_report(y_test,pred))"
      ],
      "metadata": {
        "id": "E7e8Ug5ci7hs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# New Section"
      ],
      "metadata": {
        "id": "iLcEe8tQmZCZ"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "DmwX1EZZi7fA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "SixZqlc8i7ck"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "oUFRgM5Zi7Zt"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}